defaults: &defaults
  docker:
    - image: continuumio/miniconda3
  environment:
    DATABASE_DIR: /databases
    WORKING_DIR: .test/Dryrun
    N_THREADS: 4
    MEM: 4

version: 2

jobs:
  build:
    <<: *defaults
    parallelism: 1
    steps:
      - checkout
      - run: pwd
      - run:
          name: Setup conda
          command: |
           conda config --add channels bioconda
           conda config --add channels conda-forge
           conda config --set always_yes true
      - restore_cache:
          key: atlasenv-dependencies-{{ checksum "atlasenv.yml" }}
      - run:
          name: install dependencies
          command:  |
              if [ -d "/atlasenv" ]; then
                echo "atlasenv exist already";
                source activate /atlasenv
                conda list
              else
                conda create -p /atlasenv --file atlasenv.yml
              fi
      - save_cache:
          key: atlasenv-dependencies-{{ checksum "atlasenv.yml" }}
          paths:
            - "/atlasenv"
      - run:
          name: Install atlas
          command: |
              source activate /atlasenv
              python setup.py install
              conda list
              atlas --help
              atlas --version
      - run:
          name: short test
          command: |
              source activate /atlasenv
              atlas --help
              atlas --version
      - run: |
            source activate /atlasenv
            atlas download --db-dir $DATABASE_DIR -n
      - run:
          name: Init
          command: |
              source activate /atlasenv
              atlas init --db-dir $DATABASE_DIR --threads 3 -w  $WORKING_DIR .test/reads/empty
      - run:
          name: Dryrun
          command: |
              source activate /atlasenv
              atlas run -w $WORKING_DIR --dryrun $@

      - persist_to_workspace:
          root: /
          paths:
            - atlasenv
            - databases
            - root/project

  dryrun:
    <<: *defaults
    parallelism: 1
    steps:
      - attach_workspace:
          at: /
      - run: |
          ls
          pwd
      - run:
          name: Dryrun
          command: |
              source activate /atlasenv
              .test/dryrun.sh
  getenvs:
    <<: *defaults
    parallelism: 1
    steps:
      - attach_workspace:
          at: /
      - run: cd /root/project/
      - run: tar -cf conda_envs.tar atlas/envs
      - restore_cache:
          key: conda-envs-{{ checksum "conda_envs.tar"  }}
      - run:
          name: Init
          command: |
              source activate /atlasenv
              atlas init --db-dir $DATABASE_DIR --threads 1 -w .test/Getenvs .test/reads/empty

      - run:
          name: install environements
          command: |
              source activate /atlasenv
              atlas run all -w .test/Getenvs --create-envs-only
      - save_cache:
          key: conda-envs-{{ checksum "conda_envs.tar"  }}
          paths:
            - $DATABASE_DIR
      - persist_to_workspace:
          root: /
          paths:
            - atlasenv
            - databases
            - root/project

# download checkm data
#              atlas run None -w .test/Getenvs logs/checkm_init.txt

  assembly:
    <<: *defaults
    parallelism: 4
    steps:
      - attach_workspace:
          at: /
      - run: git clone https://github.com/metagenome-atlas/example_data.git
      - run:
          name: test assembly
          command: |
              source activate /atlasenv
              .test/test_assembly.sh




workflows:
  version: 2
  build_and_test:
    jobs:
      - build
      - dryrun:
          requires:
            - build
      - getenvs:
          requires:
            - build
      - assembly:
          requires:
            - dryrun
