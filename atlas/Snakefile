import os
import re
import sys
import tempfile


NORMALIZATION_KMER_LENGTH = 21
NORMALIZATION_TARGET_DEPTH = 100


def get_conda_envs_dir():
    try:
        import atlas
    except ImportError:
        sys.exit("Unable to import python package 'atlas'; install using: pip install pnnl-atlas")
    yaml_dir = os.path.join(os.path.dirname(os.path.abspath(atlas.__file__)), "envs")
    if not os.path.exists(yaml_dir):
        sys.exit("Unable to locate the environmental dependencies file; tried %s" % yaml_dir)
    return yaml_dir


def get_assembler(config):
    norm_str = "normalization_k{length}_t{depth}".format(
                   length=config.get("normalization_kmer_length", NORMALIZATION_KMER_LENGTH),
                   depth=config.get("normalization_target_depth", NORMALIZATION_TARGET_DEPTH))
    if config.get("assembler") == "spades":
        assembler_str = "spades_{k}".format(k=config.get("spades_k", "auto").replace(",", "_"))
    else:
        k_min = config.get("megahit_k_min", 21)
        k_max = config.get("megahit_k_max", 121)
        k_step = config.get("megahit_k_step", 20)
        assembler_str = "megahit_{min}_{max}_{step}".format(min=k_min, max=k_max, step=k_step)
    return "{assembler}_{norm}".format(assembler=assembler_str, norm=norm_str)


def get_temp_dir(config):
    if config.get("tmpdir"):
        tmp_dir = config["tmpdir"]
    else:
        tmp_dir = tempfile.gettempdir()
    return tmp_dir


def get_contaminant_output_files(samples, config):
    ret_str = ""
    if "contaminant_references" in config.keys():
        if len(config["contaminant_references"]) > 0:
            ret_str = expand("{sample}/quality_control/{sample}_02_{decon_dbs}.fastq.gz",
                          sample=samples, decon_dbs=list(config["contaminant_references"].keys()))
    return ret_str


def get_bin_summary_files(do_binning, samples, assembler):
    ret_str = ""
    if do_binning:
        ret_str = expand("{sample}/{assembler}/genomic_bins/{sample}.summary",
                      sample=samples, assembler=assembler)
    return ret_str


def get_shell_prefix(config, override={}):
    pfx = config.get("prefix")
    if not pfx:
        return ""

    keys = re.findall(r"__(\w+)__", pfx)
    for k in keys:
        if k in override:
            v = override[k]
        else:
            v = config.get(k, "")
        pfx = pfx.replace("__{key}__".format(key=k), str(v))
    return pfx


def update_config_file_paths(config):
    for sample in config["samples"]:
        try:
            # convert string into list
            if isinstance(config["samples"][sample]["fastq"], str):
                config["samples"][sample]["fastq"] = [config["samples"][sample]["fastq"]]
        # fastq is not required for annotation alone
        except KeyError:
            continue
    return config


CONDAENV = get_conda_envs_dir()


if config.get("workflow", "complete") == "complete":
    config = update_config_file_paths(config)
    SHPFXM = get_shell_prefix(config)
    SHPFXS = get_shell_prefix(config, {"threads": "1"})

    # TABLES = get_count_tables(config, "summary_counts")
    TMPDIR = get_temp_dir(config)
    NORMALIZATION = "normalization_k{length}_t{depth}".format(
                        length=config.get("normalization_kmer_length", NORMALIZATION_KMER_LENGTH),
                        depth=config.get("normalization_target_depth", NORMALIZATION_TARGET_DEPTH))
    ASSEMBLER = get_assembler(config)

    SAMPLES = [i for i in config["samples"].keys()]

    wildcard_constraints:
        sample = "[\w-]+"


    rule all:
        input:
            get_contaminant_output_files(SAMPLES, config),
            expand("{sample}/quality_control/{sample}_decontamination_reference_stats.txt",
                sample=SAMPLES),
            expand("{sample}/quality_control/{sample}_00_se.fastq.gz",
                sample=SAMPLES),
            expand("{sample}/logs/{sample}_quality_filtering_stats.txt",
                sample=SAMPLES),
            expand("{sample}/{assembler}/contig_stats/prefilter_contig_stats.txt",
                sample=SAMPLES,
                assembler=ASSEMBLER),
            expand("{sample}/{assembler}/contig_stats/final_contig_stats.txt",
                sample=SAMPLES,
                assembler=ASSEMBLER),
            get_bin_summary_files(config.get("perform_genome_binning", True), SAMPLES, ASSEMBLER),
            expand("{sample}/{assembler}/functional_annotation/{sample}_annotations.txt",
                sample=SAMPLES,
                assembler=ASSEMBLER)

    include: "rules/assemble.snakefile"

elif config.get("workflow") == "download":

    FILES = ["silva_rfam_all_rRNAs.fa", "adapters.fa", "phiX174_virus.fa", "refseq.db",
             "refseq.dmnd", "refseq.tree"]

    rule all:
        input:
            expand("{dir}/{filename}", dir=os.path.realpath(config["db_dir"]), filename=FILES)

    include: "rules/download.snakefile"

elif config.get("workflow") == "annotate":
    config = update_config_file_paths(config)
    SAMPLES = list(config["samples"].keys())
    TMPDIR = get_temp_dir(config)
    SHPFXM = get_shell_prefix(config)
    SHPFXS = get_shell_prefix(config, {"threads": "1"})

    rule all:
        input:
            expand("{sample}_annotations.txt", sample=SAMPLES),
            expand("{sample}/contig_stats.txt", sample=SAMPLES)

    include: "rules/annotate.snakefile"

else:
    print("Workflow %s is not a defined workflow." % config.get("workflow", "[no --workflow specified]"),
          file=sys.stderr)
